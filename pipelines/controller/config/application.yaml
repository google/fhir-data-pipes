#
# Copyright 2020-2022 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

fhirdata:
  # This is the base URL of the FHIR server; 172.17.0.1 is an example docker
  # network interface address.
  fhirServerUrl: "http://172.17.0.1:8091/fhir"

  dbConfig: "config/hapi-postgres-config.json"

  # for GCS file system the dwhRootPrefix should be of the format
  # "gs://<bucket>/<baseDirPath>/<prefix>"
  # for Unix file system the dwhRootPrefix should be of the format "/<baseDirPath>/<prefix>
  # dwhRootPrefix: "gs://fhir-test-analytics/config/controller_DWH_ORIG"
  dwhRootPrefix: "config/controller_DWH_ORIG"

  thriftserverHiveConfig: "config/thriftserver-hive-config.json"

  # The schedule format is similar to Spring's CronExpression, i.e.,
  # "second minute hour day-of-the-month month day-of-the-week", e.g.,
  # "0 0 * * * *" means top of every hour;
  # "*/40 * * * * *" means every 40 seconds;
  # Note a too frequent run might be too resource intensive.
  incrementalSchedule: "0 0 * * * *"

  # cron expression to trigger the purge job which handles the ttl of dwh snapshots
  purgeSchedule: "0 0 * * * *"

  # The number of dwh snapshots to be retained when the purge job runs
  numOfDwhSnapshotsToRetain: 2

  # Comma separated list of resources to fetch/monitor.
  resourceList: "Patient,Encounter,Observation"

  maxWorkers: 10

  createHiveResourceTables: false

  hiveJdbcDriver: "org.apache.hive.jdbc.HiveDriver"
